Problem ID: abc354_c
Problem Content:
Takahashi has N cards from the card game "AtCoder Magics." The i-th card will be called card i. Each card has two parameters: strength and cost. Card i has a strength of A_i and a cost of C_i.
He does not like weak cards, so he will discard them. Specifically, he will repeat the following operation until it can no longer be performed:

- Choose two cards x and y such that A_x > A_y and C_x < C_y. Discard card y.

It can be proved that the set of remaining cards when the operations can no longer be performed is uniquely determined. Find this set of cards.

Input

The input is given from Standard Input in the following format:
N
A_1 C_1
A_2 C_2
\vdots
A_N C_N

Output

Let there be m remaining cards, cards i_1, i_2, \dots, i_m, in ascending order. Print these in the following format:
m
i_1 i_2 \cdots i_m

Constraints


- 2 \leq N \leq 2 \times 10^5
- 1 \leq A_i, C_i \leq 10^9
- A_1, A_2, \dots ,A_N are all distinct.
- C_1, C_2, \dots ,C_N are all distinct.
- All input values are integers.

Sample Input 1

3
2 4
1 1
3 2

Sample Output 1

2
2 3

Focusing on cards 1 and 3, we have A_1 < A_3 and C_1 > C_3, so card 1 can be discarded.
No further operations can be performed. At this point, cards 2 and 3 remain, so print them.

Sample Input 2

5
1 1
10 2
100 3
1000 4
10000 5

Sample Output 2

5
1 2 3 4 5

In this case, no cards can be discarded.

Sample Input 3

6
32 101
65 78
2 29
46 55
103 130
52 40

Sample Output 3

4
2 3 5 6

Qwen2 Analysis:
The problem described involves sorting, data structure manipulation (specifically with priority queues), and understanding of algorithmic concepts like greedy algorithms or sorting principles.

**Category Prediction:**

1. **Difficulty:** The problem is at a **medium-high** level based on the constraints provided (e.g., N can be up to 2*10^5). The main challenge lies in handling large datasets efficiently while maintaining the integrity of the operation logic described.

2. **Required Programming Skills:** Solving this requires **competence in data structure usage**, specifically the ability to implement or use a priority queue effectively, since you're sorting items based on certain conditions repeatedly and removing elements under specific criteria without affecting their order too much (since only adjacent elements are being removed based on strength and cost). 

3. **Complexity:** The time complexity is critical here due to large N constraints. Ideally, the solution should be able to handle operations in O(N logN) or better if possible using more advanced techniques like sorting with specific requirements.

**Solution Approach:**

This problem would generally fall under the category of `Algorithm Design and Implementation` focusing on `Data Structures & Algorithms`, particularly those involving sorting (possibly enhanced by a priority queue or a form of selection algorithm that takes into account both strength and cost), understanding data dependencies, and handling large data sets efficiently.

**Additional Notes:**

- **Sorting:** The greedy aspect implies that at each step, the best choice seems to be removing the card with the least cost for which there exists a stronger card. This points towards maintaining a dynamic set or using a sorted list that can be updated (or reorganized) during execution without losing efficiency.
  
- **Optimization:** Since direct sorting might not suffice due to constraints and complexity, an optimized approach would involve keeping track of potential candidates for removal while inserting new cards into the optimal position based on their strength and cost compared to existing ones.

Given these observations:

**Category:**
*Algorithm Design & Implementation > Data Structures & Algorithms > Optimization & Greedy Algorithms*

This categorization highlights the core skills and concepts required to solve such a problem efficiently.
